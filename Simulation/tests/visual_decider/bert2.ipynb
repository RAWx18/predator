{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import pandas as pd\n",
    "import random, time\n",
    "from babel.dates import format_date, format_datetime, format_time\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import transformers, os\n",
    "from transformers import BertModel, AutoModel, AdamW, get_linear_schedule_with_warmup, BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check device \n",
    "# Get the GPU device name if available.\n",
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('GPU(s) available: {}'.format(torch.cuda.device_count()))\n",
    "    print('We will use the GPU: {}'.format(torch.cuda.get_device_name(0)))\n",
    "\n",
    "# If we dont have GPU but a CPU, training will take place on CPU instead\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "torch.cuda.empty_cache()\n",
    "    \n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data/Dataset_unsupervised.csv\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get to Know the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Camera').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=df['Camera'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordcloud of text\n",
    "\n",
    "# Get stopwords\n",
    "# Define nltk stopwords in english\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "# Get a string of all the texts available\n",
    "data_text = \",\".join(txt.lower() for txt in df.Command)\n",
    "\n",
    "# Create and generate a word cloud image:\n",
    "wordcloud = WordCloud(max_font_size=50, \n",
    "                      max_words=100, \n",
    "                      stopwords=stop_words,\n",
    "                      scale=5,\n",
    "                      background_color=\"white\").generate(data_text)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title('Most repeated words in all Commands',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Downsampling data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nocam = df[df['Camera']==0]\n",
    "df_cam = df[df['Camera']==1]\n",
    "df_cam_downsampled = df_cam.sample(df_nocam.shape[0])\n",
    "df = pd.concat([df_cam_downsampled, df_nocam])\n",
    "df.groupby('Camera').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split test and train data using 25% of the dataset for validation purposes\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['Command'], df['Camera'], test_size=0.25, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try transformer model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a 10% test set from train set\n",
    "X_train_Transformer, X_val_Transformer, y_train_Transformer, y_val_Transformer = train_test_split(x_train, y_train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "SEQ_LEN = 200\n",
    "batch_size = 16\n",
    "epochs = 5\n",
    "learning_rate = 1e-5 # Controls how large a step is taken when updating model weights during training.\n",
    "steps_per_epoch = 50\n",
    "num_workers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the RoBERTa tokenizer and tokenize the data\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trencoding = tokenizer.batch_encode_plus(\n",
    "  list(X_train_Transformer),\n",
    "  max_length=SEQ_LEN,\n",
    "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "  return_token_type_ids=True,\n",
    "  truncation=True,\n",
    "  padding='longest',\n",
    "  return_attention_mask=True,\n",
    ")\n",
    "\n",
    "valencoding = tokenizer.batch_encode_plus(\n",
    "  list(X_val_Transformer),\n",
    "  max_length=SEQ_LEN,\n",
    "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "  return_token_type_ids=True,\n",
    "  truncation=True,\n",
    "  padding='longest',\n",
    "  return_attention_mask=True,\n",
    ")\n",
    "\n",
    "\n",
    "testencoding = tokenizer.batch_encode_plus(\n",
    "  list(x_test),\n",
    "  max_length=SEQ_LEN,\n",
    "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "  return_token_type_ids=True,\n",
    "  truncation=True,\n",
    "  padding='longest',\n",
    "  return_attention_mask=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trencoding.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find Class Weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the class weights\n",
    "class_wts = compute_class_weight(class_weight='balanced', classes=np.unique(df['Camera'].values.tolist()), y=df['Camera'])\n",
    "\n",
    "#print(class_wts)\n",
    "\n",
    "# convert class weights to tensor\n",
    "weights= torch.tensor(class_wts,dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "\n",
    "# loss function\n",
    "#cross_entropy  = nn.NLLLoss(weight=weights) \n",
    "cross_entropy  = nn.CrossEntropyLoss(weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(prep_df, batch_size, num_workers, sampler):\n",
    "    \n",
    "    return  DataLoader(\n",
    "            prep_df,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=num_workers,\n",
    "            sampler=sampler,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "## convert lists to tensors\n",
    "train_seq = torch.tensor(trencoding['input_ids'])\n",
    "train_mask = torch.tensor(trencoding['attention_mask'])\n",
    "train_token_ids = torch.tensor(trencoding['token_type_ids'])\n",
    "train_y = torch.tensor(y_train_Transformer.tolist())\n",
    "\n",
    "val_seq = torch.tensor(valencoding['input_ids'])\n",
    "val_mask = torch.tensor(valencoding['attention_mask'])\n",
    "val_token_ids = torch.tensor(valencoding['token_type_ids'])\n",
    "val_y = torch.tensor(y_val_Transformer.tolist())\n",
    "\n",
    "test_seq = torch.tensor(testencoding['input_ids'])\n",
    "test_mask = torch.tensor(testencoding['attention_mask'])\n",
    "test_token_ids = torch.tensor(testencoding['token_type_ids'])\n",
    "test_y = torch.tensor(y_test.tolist())\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_token_ids, train_y)\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "# Train Data Loader\n",
    "traindata = loadData(train_data, batch_size, num_workers, train_sampler)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_token_ids, val_y)\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "# Val Data Loader\n",
    "valdata = loadData(val_data, batch_size, num_workers, val_sampler)\n",
    "\n",
    "# wrap tensors\n",
    "test_data = TensorDataset(test_seq, test_mask, test_token_ids, test_y)\n",
    "# sampler for sampling the data during training\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "# Val Data Loader\n",
    "testdata = loadData(test_data, batch_size, num_workers, test_sampler)\n",
    "\n",
    "\n",
    "print('Number of data in the train set', len(traindata))\n",
    "print('Number of data in the validation set', len(valdata))\n",
    "print('Number of data in the test set', len(testdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load BERT model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes, freeze_bert=False):\n",
    "        \n",
    "        super(BERT_Arch,self).__init__()\n",
    "        # Instantiating BERT model object\n",
    "        self.bert = BertModel.from_pretrained(model_name, return_dict=False)\n",
    "        \n",
    "        # Freeze bert layers\n",
    "        if freeze_bert:\n",
    "            for p in self.bert.parameters():\n",
    "                p.requires_grad = False\n",
    "                \n",
    "        self.bert_drop_1 = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size) # (768, 64)\n",
    "        self.bn = nn.BatchNorm1d(768) # (768)\n",
    "        self.bert_drop_2 = nn.Dropout(0.25)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes) # (768,2)\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        _, output = self.bert(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            token_type_ids = token_type_ids\n",
    "        )\n",
    "        output = self.bert_drop_1(output)\n",
    "        output = self.fc(output)\n",
    "        output = self.bn(output)\n",
    "        output = self.bert_drop_2(output)\n",
    "        output = self.out(output)        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.unique(df['Camera'])\n",
    "print('Downloading the BERT custom model...')\n",
    "model = BERT_Arch(len(class_names))\n",
    "model.to(device) # Model to GPU.\n",
    "\n",
    "#optimizer parameters\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "optimizer_parameters = [{'params': [p for n, p in param_optimizer \n",
    "                                    if not any(nd in n for nd in no_decay)],'weight_decay':0.001},\n",
    "                        {'params': [p for n, p in param_optimizer \n",
    "                                    if any(nd in n for nd in no_decay)],'weight_decay':0.0}]\n",
    "\n",
    "print('Preparing the optimizer...')\n",
    "#optimizer \n",
    "optimizer = AdamW(optimizer_parameters, lr=learning_rate)\n",
    "steps = steps_per_epoch\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the bert model\n",
    "def trainBERT():\n",
    "  \n",
    "    print('Training...')\n",
    "    model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    # empty list to save model predictions\n",
    "    total_preds=[]\n",
    "\n",
    "    # iterate over batches\n",
    "    for step, batch in enumerate(traindata):\n",
    "    \n",
    "        # progress update after every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(traindata)))\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            # push the batch to gpu\n",
    "            batch = [r.to(device) for r in batch]\n",
    "\n",
    "        sent_id, mask, token_type_ids, labels = batch\n",
    "        # clear previously calculated gradients \n",
    "        model.zero_grad()        \n",
    "        # get model predictions for the current batch\n",
    "        preds = model(sent_id, mask, token_type_ids)\n",
    "        # compute the loss between actual and predicted values\n",
    "        loss = cross_entropy(preds, labels)\n",
    "        # add on to the total loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        # model predictions are stored on GPU. So, push it to CPU\n",
    "        preds=preds.detach().cpu().numpy()\n",
    "        # append the model predictions\n",
    "        total_preds.append(preds)\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / len(traindata)\n",
    "\n",
    "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    #returns the loss and predictions\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "  \n",
    "    print(\"\\nEvaluating...\")\n",
    "    t0 = time.time()\n",
    "    \n",
    "    model.eval() # deactivate dropout layers\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    \n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "\n",
    "    # iterate over batches\n",
    "    for step, batch in enumerate(valdata):\n",
    "        # Progress update every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(valdata)))\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            # push the batch to gpu\n",
    "            batch = [t.to(device) for t in batch]\n",
    "\n",
    "        sent_id, mask, token_type_ids, labels = batch\n",
    "\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad(): # Dont store any previous computations, thus freeing GPU space\n",
    "\n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask, token_type_ids)\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = cross_entropy(preds, labels)\n",
    "            total_loss = total_loss + loss.item()\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            total_preds.append(preds)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(valdata) \n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# Empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "# for each epoch perform training and evaluation\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = trainBERT()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    print('Evaluation done for epoch {}'.format(epoch + 1))\n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        print('Saving model...')\n",
    "        torch.save(model.state_dict(), 'bert_weights.pt') # Save model weight's (you can also save it in .bin format)\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nTest Set...')\n",
    "\n",
    "test_preds = []\n",
    "\n",
    "print('Total batches:', len(testdata))\n",
    "\n",
    "for fold_index in range(0, 3):\n",
    "    \n",
    "    print('\\nFold Model', fold_index)\n",
    "    \n",
    "    # Load the fold model\n",
    "    path_model = 'bert_weights.pt'\n",
    "    model.load_state_dict(torch.load(path_model))\n",
    "\n",
    "    # Send the model to the GPU\n",
    "    model.to(device)\n",
    "\n",
    "    stacked_val_labels = []\n",
    "    \n",
    "    # Put the model in evaluation mode.\n",
    "    model.eval()\n",
    "\n",
    "    # Turn off the gradient calculations.\n",
    "    # This tells the model not to compute or store gradients.\n",
    "    # This step saves memory and speeds up validation.\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_val_loss = 0\n",
    "\n",
    "    for j, test_batch in enumerate(testdata):\n",
    "\n",
    "        inference_status = 'Batch ' + str(j + 1)\n",
    "\n",
    "        print(inference_status, end='\\r')\n",
    "\n",
    "        b_input_ids = test_batch[0].to(device)\n",
    "        b_input_mask = test_batch[1].to(device)\n",
    "        b_token_type_ids = test_batch[2].to(device)\n",
    "        b_test_y = test_batch[3].to(device)\n",
    "\n",
    "\n",
    "        outputs = model(b_input_ids, \n",
    "                        attention_mask=b_input_mask,\n",
    "                        token_type_ids=b_token_type_ids)\n",
    "\n",
    "        # Get the preds\n",
    "        preds = outputs[0]\n",
    "\n",
    "        # Move preds to the CPU\n",
    "        val_preds = preds.detach().cpu().numpy()\n",
    "        \n",
    "        #true_labels.append(b_test_y.to('cpu').numpy().flatten())\n",
    "        \n",
    "        # Stack the predictions.\n",
    "        if j == 0:  # first batch\n",
    "            stacked_val_preds = val_preds\n",
    "            \n",
    "        else:\n",
    "            stacked_val_preds = np.vstack((stacked_val_preds, val_preds))\n",
    "            \n",
    "    test_preds.append(stacked_val_preds)\n",
    "    \n",
    "            \n",
    "print('\\nPrediction complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_preds))\n",
    "print(test_preds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the predictions of all fold models\n",
    "for i, item in enumerate(test_preds):\n",
    "    if i == 0:\n",
    "        preds = item\n",
    "    else:\n",
    "        # Sum the matrices\n",
    "        preds = item + preds\n",
    "\n",
    "# Average the predictions\n",
    "avg_preds = preds/(len(test_preds))\n",
    "\n",
    "#print(preds)\n",
    "#print()\n",
    "#print(avg_preds)\n",
    "\n",
    "# Take the argmax. \n",
    "# This returns the column index of the max value in each row.\n",
    "test_predictions = np.argmax(avg_preds, axis=1)\n",
    "\n",
    "# Take a look of the output\n",
    "print(type(test_predictions))\n",
    "print(len(test_predictions))\n",
    "print()\n",
    "print(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_y = []\n",
    "for j, test_batch in enumerate(testdata):\n",
    "    true_y.append(int(test_batch[3][0].numpy().flatten()))\n",
    "print(true_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy and classification report \n",
    "target_names = ['true_y', 'predicted_y']\n",
    "\n",
    "data = {'true_y': true_y,\n",
    "       'predicted_y': test_predictions}\n",
    "\n",
    "df_pred_BERT = pd.DataFrame(data, columns=['true_y','predicted_y'])\n",
    "\n",
    "confusion_matrix = pd.crosstab(df_pred_BERT['true_y'], df_pred_BERT['predicted_y'], rownames=['True'], colnames=['Predicted'])\n",
    "\n",
    "sns.heatmap(confusion_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of BERT model', accuracy_score(true_y, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(true_y, test_predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pipeline with the TfidfVectorizer and LogisticRegression model\n",
    "LR_pipeline = Pipeline(steps = [('tf', TfidfVectorizer()), \n",
    "                                ('lgrg', LogisticRegression())]) # initialize TfidfVectorizer and LogisticRegression\n",
    "\n",
    "\n",
    "# Create Parameter Grid\n",
    "pgrid_lgrg = {\n",
    " 'tf__max_features' : [1000, 2000, 3000],\n",
    " 'tf__ngram_range' : [(1,1),(1,2)],\n",
    " 'tf__use_idf' : [True, False],\n",
    " 'lgrg__penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    " 'lgrg__class_weight' : ['balanced', None]\n",
    "}\n",
    "\n",
    "# Apply GridSearch to Pipeline to find the best parameters\n",
    "gs_lgrg = GridSearchCV(LR_pipeline, pgrid_lgrg, cv=2, n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_lgrg.fit(x_train, y_train) # Train LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_lgrg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Score of train set', gs_lgrg.score(x_train, y_train))\n",
    "print('Score of test set',gs_lgrg.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_pred = gs_lgrg.predict(x_test) # Predict on validation data\n",
    "\n",
    "data = {'true_y': y_test,\n",
    "       'predicted_y': LR_pred}\n",
    "df_pred = pd.DataFrame(data, columns=['true_y','predicted_y'])\n",
    "confusion_matrix = pd.crosstab(df_pred['true_y'], df_pred['predicted_y'], rownames=['True'], colnames=['Predicted'])\n",
    "\n",
    "sns.heatmap(confusion_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of LR model', accuracy_score(y_test, LR_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, LR_pred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
